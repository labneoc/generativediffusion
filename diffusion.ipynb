{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from plotting_utils import (\n",
    "    plot_sd,\n",
    "    basic_plotting,\n",
    "    plot_overlapping_signal\n",
    ")\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir seed global\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processo de Ruído (OUProcess)\n",
    "class OUProcess:\n",
    "    def __init__(self, sigma_squared, ell, signal_length):\n",
    "        self.sigma_squared = sigma_squared\n",
    "        self.ell = ell\n",
    "        self.signal_length = signal_length\n",
    "\n",
    "    def sample(self, shape):\n",
    "        dt = 1 / self.signal_length\n",
    "        noise = np.random.normal(\n",
    "            0, np.sqrt(self.sigma_squared * (1 - np.exp(-2 * self.ell * dt))), size=shape\n",
    "        )\n",
    "        return torch.tensor(noise, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Difusão\n",
    "class DiffusionModel:\n",
    "    def __init__(self, num_steps, beta_start, beta_end, noise_sampler):\n",
    "        self.num_steps = num_steps\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_steps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.noise_sampler = noise_sampler\n",
    "\n",
    "    def forward_diffusion(self, data, t):\n",
    "        noise = self.noise_sampler.sample(data.shape)\n",
    "        alpha_t = self.alphas_cumprod[t].view(-1, 1, 1)\n",
    "        noisy_data = (\n",
    "            torch.sqrt(alpha_t) * data +\n",
    "            torch.sqrt(1.0 - alpha_t) * noise\n",
    "        )\n",
    "        return noisy_data, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural de Denoising (CatConv)\n",
    "class CatConv(nn.Module):\n",
    "    def __init__(self, signal_length, signal_channel, hidden_channel, kernel_size):\n",
    "        super(CatConv, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(signal_channel, hidden_channel, kernel_size, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_channel, hidden_channel, kernel_size, padding=1)\n",
    "        self.conv3 = nn.Conv1d(hidden_channel, signal_channel, kernel_size, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset para EEG\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_files = [\n",
    "            np.load(os.path.join(data_dir, file)) for file in os.listdir(data_dir) if file.endswith('.npy')\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_files[idx]\n",
    "        if data.ndim == 1:  # Adicionar dimensão do canal\n",
    "            data = np.expand_dims(data, axis=0)\n",
    "        return torch.tensor(data, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de Treinamento\n",
    "def train_model(diffusion, denoiser, dataset, num_epochs, batch_size, lr, seed):\n",
    "    set_seed(seed)  # Definir seed\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.Adam(denoiser.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for data in dataloader:\n",
    "            t = torch.randint(0, diffusion.num_steps, (data.shape[0],)).long()\n",
    "            noisy_data, noise = diffusion.forward_diffusion(data, t)\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise = denoiser(noisy_data)\n",
    "            loss = criterion(predicted_noise, noise)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração de Dados Sintéticos\n",
    "def generate_synthetic_data(diffusion, denoiser, sample_shape, num_samples):\n",
    "    samples = []\n",
    "    for _ in range(num_samples):\n",
    "        noisy_sample = torch.randn(sample_shape)\n",
    "        for t in reversed(range(diffusion.num_steps)):\n",
    "            noisy_sample = denoiser(noisy_sample)\n",
    "        samples.append(noisy_sample)\n",
    "    return torch.stack(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para Salvar e Plotar\n",
    "def generate_and_save_plots(real_data, synthetic_data, channels, fs, output_dir=\"./results\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Garantir que os sinais estão na forma correta\n",
    "    real_signal = real_data.mean(axis=0).squeeze()  # Sinais médios reais\n",
    "    synthetic_signal = synthetic_data.mean(axis=0).squeeze()  # Sinais médios sintéticos\n",
    "\n",
    "    # Recalcular o eixo do tempo com base no tamanho de real_signal\n",
    "    time = np.linspace(0, len(real_signal) / fs, len(real_signal))\n",
    "\n",
    "    # Interpolar o sinal sintético para coincidir com o tempo e real_signal\n",
    "    if len(synthetic_signal) != len(real_signal):\n",
    "        interp_func = interp1d(\n",
    "            np.linspace(0, 1, len(synthetic_signal)),\n",
    "            synthetic_signal,\n",
    "            kind=\"linear\",\n",
    "            fill_value=\"extrapolate\",\n",
    "        )\n",
    "        synthetic_signal = interp_func(np.linspace(0, 1, len(real_signal)))\n",
    "\n",
    "    # Verificação de dimensões\n",
    "    if len(time) != len(real_signal) or len(time) != len(synthetic_signal):\n",
    "        raise ValueError(\n",
    "            f\"Dimensões incompatíveis: time ({len(time)}), \"\n",
    "            f\"real_signal ({len(real_signal)}), \"\n",
    "            f\"synthetic_signal ({len(synthetic_signal)})\"\n",
    "        )\n",
    "\n",
    "    # Plotagem básica: Real vs Sintético\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(time, real_signal, label=\"Real Data\")\n",
    "    ax.plot(time, synthetic_signal, label=\"Synthetic Data\")\n",
    "    basic_plotting(\n",
    "        fig,\n",
    "        ax,\n",
    "        x_label=\"Time (s)\",\n",
    "        y_label=\"Amplitude\",\n",
    "    )\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Real vs Synthetic Data\")\n",
    "    plt.savefig(f\"{output_dir}/basic_plotting.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Plotagem de densidade espectral\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    plot_sd(\n",
    "        fig,\n",
    "        ax,\n",
    "        arr_one=real_data.squeeze(1),\n",
    "        arr_two=synthetic_data.squeeze(1),\n",
    "        fs=fs,\n",
    "        nperseg=256,\n",
    "        with_quantiles=True\n",
    "    )\n",
    "    plt.title(\"Spectral Density Comparison\")\n",
    "    plt.savefig(f\"{output_dir}/spectral_density_comparison.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Plotagem de sinais sobrepostos\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    plot_overlapping_signal(fig, ax, sig=synthetic_data[0, :, :])\n",
    "    plt.title(\"Overlapping Signals - Synthetic Data\")\n",
    "    plt.savefig(f\"{output_dir}/overlapping_signal.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Gráficos salvos na pasta: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0087\n",
      "Epoch 2/10, Loss: 0.0037\n",
      "Epoch 3/10, Loss: 0.0036\n",
      "Epoch 4/10, Loss: 0.0027\n",
      "Epoch 5/10, Loss: 0.0012\n",
      "Epoch 6/10, Loss: 0.0003\n",
      "Epoch 7/10, Loss: 0.0005\n",
      "Epoch 8/10, Loss: 0.0009\n",
      "Epoch 9/10, Loss: 0.0010\n",
      "Epoch 10/10, Loss: 0.0009\n",
      "Gráficos salvos na pasta: ./results\n"
     ]
    }
   ],
   "source": [
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "    # Parâmetros\n",
    "    num_steps = 100\n",
    "    beta_start = 1e-4\n",
    "    beta_end = 0.02\n",
    "    signal_length = 256\n",
    "    signal_channel = 1\n",
    "    hidden_channel = 64\n",
    "    kernel_size = 3\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "    lr = 1e-3\n",
    "    num_samples = 5\n",
    "    seed = 42  # Seed global\n",
    "\n",
    "    # Configuração de Seed\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Processo de Ruído\n",
    "    noise_sampler = OUProcess(sigma_squared=0.02, ell=0.1, signal_length=signal_length)\n",
    "\n",
    "    # Modelo de Difusão\n",
    "    diffusion = DiffusionModel(num_steps, beta_start, beta_end, noise_sampler)\n",
    "\n",
    "    # Rede de Denoising\n",
    "    denoiser = CatConv(\n",
    "        signal_length=signal_length,\n",
    "        signal_channel=signal_channel,\n",
    "        hidden_channel=hidden_channel,\n",
    "        kernel_size=kernel_size,\n",
    "    )\n",
    "\n",
    "    # Dataset\n",
    "    dataset = EEGDataset(data_dir='/Users/analuiza/Documents/codes/templedata/00007656_s010_t000_processed_data')  # Substitua pelo caminho correto\n",
    "\n",
    "    # Treinamento\n",
    "    train_model(diffusion, denoiser, dataset, num_epochs=num_epochs, batch_size=batch_size, lr=lr, seed=seed)\n",
    "\n",
    "    # Geração de Dados Sintéticos\n",
    "    synthetic_data = generate_synthetic_data(diffusion, denoiser, sample_shape=(signal_channel, signal_length), num_samples=num_samples)\n",
    "\n",
    "    # Plotagens\n",
    "    real_data = torch.stack([dataset[i] for i in range(3)]).numpy()\n",
    "    synthetic_data_np = synthetic_data.detach().numpy()\n",
    "    generate_and_save_plots(real_data, synthetic_data_np, channels=[\"Fp1\", \"Fp2\", \"C3\"], fs=256, output_dir=\"./results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

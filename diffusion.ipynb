{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Configurações do Processo de Ornstein-Uhlenbeck\n",
    "# ==============================================\n",
    "\n",
    "class OUProcess:\n",
    "    def __init__(self, num_channels, seq_length, rho=0.1, sigma=0.2):\n",
    "        self.rho = rho\n",
    "        self.sigma = sigma\n",
    "        self.num_channels = num_channels\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # Pré-computa a matriz de precisão tridiagonal\n",
    "        self.precision_matrix = self._construct_precision_matrix()\n",
    "        \n",
    "    def _construct_precision_matrix(self):\n",
    "        \"\"\"Constrói a matriz de precisão do processo OU (tridiagonal).\"\"\"\n",
    "        diag = (1 + self.rho**2) * torch.eye(self.seq_length)\n",
    "        off_diag = -self.rho * torch.diag(torch.ones(self.seq_length - 1), 1)  # Correção aqui\n",
    "        precision_matrix = diag + off_diag + off_diag.T\n",
    "        return precision_matrix / (self.sigma**2)\n",
    "\n",
    "\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Amostra do processo OU usando a propriedade Gauss-Markov.\"\"\"\n",
    "        x = torch.zeros(batch_size, self.num_channels, self.seq_length)\n",
    "        for t in range(1, self.seq_length):\n",
    "            x[:, :, t] = x[:, :, t-1] * (1 - self.rho) + torch.randn_like(x[:, :, t]) * self.sigma\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================\n",
    "# Módulo 1: Carregamento de Dados Neurofisiológicos\n",
    "# ==============================================\n",
    "\n",
    "class NeurophysioDataset(Dataset):\n",
    "    def __init__(self, data_dir, window_size=1000):\n",
    "        self.data_dir = data_dir\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # Carrega e empilha canais\n",
    "        self.channel_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.npy')])\n",
    "        self.channels = [np.load(os.path.join(data_dir, f)) for f in self.channel_files]\n",
    "        \n",
    "        # Alinhamento temporal\n",
    "        self.min_length = min(c.shape[0] for c in self.channels)\n",
    "        self.num_windows = self.min_length // self.window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_windows\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.window_size\n",
    "        end = start + self.window_size\n",
    "        x = np.stack([c[start:end] for c in self.channels])  # [C, L]\n",
    "        x = torch.FloatTensor(x)  # [channels, sequence_length]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Módulo 2: Arquitetura do Denoiser com Convoluções Estruturadas\n",
    "# ==============================================\n",
    "\n",
    "class StructuredConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=15, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            padding=(kernel_size//2)*dilation,\n",
    "            dilation=dilation\n",
    "        )\n",
    "        self.norm = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  # Correto! Mantém [batch, canais, seq_length]\n",
    "        x = self.norm(x)\n",
    "        return F.gelu(x)\n",
    "\n",
    "\n",
    "\n",
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, num_channels, hidden_dims=[128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        \n",
    "        # Encoder com múltiplas escalas temporais\n",
    "        self.encoder = nn.ModuleList([\n",
    "            StructuredConvBlock(num_channels, hidden_dims[0], kernel_size=31),  # 23 → 128\n",
    "            StructuredConvBlock(hidden_dims[0], hidden_dims[1], kernel_size=63),  # 128 → 256\n",
    "            StructuredConvBlock(hidden_dims[1], hidden_dims[2], kernel_size=127),  # 256 → 512 (correto!)\n",
    "         ])\n",
    "\n",
    "        \n",
    "        # Time embedding para capturar dinâmica do processo de difusão\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, 128),  # Redução inicial\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, num_channels)  # Saída deve ser igual ao número de canais de x\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Decoder com skip connections\n",
    "        self.decoder = nn.ModuleList([\n",
    "            StructuredConvBlock(hidden_dims[2] + hidden_dims[2], hidden_dims[1]),  # 512+512 → 256\n",
    "            StructuredConvBlock(hidden_dims[1] + hidden_dims[1], hidden_dims[0]),  # 256+256 → 128\n",
    "            StructuredConvBlock(hidden_dims[0] + hidden_dims[0], num_channels)  # 128+128 → 23\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "\n",
    "        skips = []\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            skips.append(x)\n",
    "\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            skip_connection = skips[-(i+1)]\n",
    "            if x.shape[1] + skip_connection.shape[1] == layer.conv.in_channels:\n",
    "                x = torch.cat([x, skip_connection], dim=1)  # Apenas se os canais forem compatíveis\n",
    "            else:\n",
    "                print(f\"❌ ERRO: Concatenação inválida! Esperado {layer.conv.in_channels}, mas recebeu {x.shape[1]} + {skip_connection.shape[1]}\")\n",
    "                exit()  # Encerra a execução para depuração\n",
    "            x = layer(x)\n",
    "\n",
    "        t_emb = self.time_embed(t.unsqueeze(1).float()).unsqueeze(-1).expand(-1, -1, x.shape[2])\n",
    "        return x + t_emb  # Injeção temporal final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Módulo 3: Processo de Difusão com OU\n",
    "# ==============================================\n",
    "\n",
    "class OU_Diffusion:\n",
    "    def __init__(self, denoiser, T=1000, rho=0.1, sigma=0.2):\n",
    "        self.denoiser = denoiser\n",
    "        self.T = T\n",
    "        self.rho = rho\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        # Cronograma de ruído adaptativo\n",
    "        self.beta = torch.linspace(1e-4, 0.02, T) * self._spectral_adjustment()\n",
    "        self.alpha = 1 - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        \n",
    "    def _spectral_adjustment(self):\n",
    "        \"\"\"Ajusta o cronograma de ruído para respeitar a lei de potência 1/f\"\"\"\n",
    "        t = torch.arange(self.T, dtype=torch.float32)\n",
    "        return 1 / (1 + t**0.5)\n",
    "    \n",
    "    def forward_process(self, x_0, t):\n",
    "        \"\"\"Processo de difusão com ruído OU\"\"\"\n",
    "        ou = OUProcess(x_0.size(1), x_0.size(2), self.rho, self.sigma)\n",
    "        noise = ou.sample(x_0.size(0))\n",
    "        \n",
    "        alpha_bar_t = self.alpha_bar[t].view(-1, 1, 1)\n",
    "        x_t = torch.sqrt(alpha_bar_t) * x_0 + torch.sqrt(1 - alpha_bar_t) * noise\n",
    "        return x_t, noise\n",
    "\n",
    "    def train_step(self, x_0, optimizer):\n",
    "        optimizer.zero_grad()\n",
    "        x_0 = x_0  # Já está no formato correto [batch, canais, seq_length]\n",
    "\n",
    "        # Amostragem do passo temporal\n",
    "        t = torch.randint(0, self.T, (x_0.size(0),))\n",
    "        \n",
    "        # Processo de difusão\n",
    "        x_t, noise = self.forward_process(x_0, t)\n",
    "        \n",
    "        # Predição do ruído\n",
    "        pred_noise = self.denoiser(x_t, t)\n",
    "        \n",
    "        # Perda com regularização espectral\n",
    "        loss = F.mse_loss(pred_noise, noise)\n",
    "        spectral_loss = self._spectral_consistency(x_0, pred_noise)\n",
    "        total_loss = loss + 0.1 * spectral_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        return total_loss.item()\n",
    "    \n",
    "    def _spectral_consistency(self, real, fake):\n",
    "        \"\"\"Perda de consistência espectral no domínio da frequência\"\"\"\n",
    "        real_fft = torch.fft.rfft(real, dim=-1).abs()\n",
    "        fake_fft = torch.fft.rfft(fake, dim=-1).abs()\n",
    "        return F.mse_loss(real_fft, fake_fft)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, num_samples, seq_length):\n",
    "        \"\"\"Amostragem reversa com processo OU\"\"\"\n",
    "        ou = OUProcess(self.denoiser.num_channels, seq_length, self.rho, self.sigma)\n",
    "        x_t = ou.sample(num_samples)\n",
    "        \n",
    "        for t in reversed(range(self.T)):\n",
    "            alpha_t = self.alpha[t]\n",
    "            alpha_bar_t = self.alpha_bar[t]\n",
    "            \n",
    "            pred_noise = self.denoiser(x_t, torch.tensor([t]*num_samples))\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = ou.sample(num_samples)\n",
    "            else:\n",
    "                noise = 0\n",
    "                \n",
    "            x_t = (x_t - (1 - alpha_t)/torch.sqrt(1 - alpha_bar_t) * pred_noise) / torch.sqrt(alpha_t)\n",
    "            x_t += torch.sqrt(self.beta[t]) * noise\n",
    "            \n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Pipeline de Treinamento e Avaliação\n",
    "# ==============================================\n",
    "\n",
    "def train(data_dir, num_epochs=500, batch_size=16):\n",
    "    dataset = NeurophysioDataset(data_dir)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    denoiser = Denoiser(num_channels=len(dataset.channel_files))\n",
    "    diffusion = OU_Diffusion(denoiser)\n",
    "    optimizer = torch.optim.AdamW(denoiser.parameters(), lr=1e-4)\n",
    "    loss_log = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        for batch in loader:\n",
    "            loss = diffusion.train_step(batch, optimizer)\n",
    "            avg_loss += loss\n",
    "        current_loss = avg_loss / len(loader)\n",
    "        loss_log.append(current_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss/len(loader):.4f}\")\n",
    "\n",
    "\n",
    "    torch.save(denoiser.state_dict(), 'denoiser.pt')\n",
    "\n",
    "    return denoiser, diffusion,loss_log\n",
    "\n",
    "def spectral_analysis(signal, fs=200):\n",
    "    \"\"\"Calcula a densidade espectral de potência\"\"\"\n",
    "    from scipy.signal import welch\n",
    "    f, psd = welch(signal, fs=fs, nperseg=512)\n",
    "    return f, psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_properties(i).name)\n",
    "       \n",
    "    # Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "denoiser, diffusion, loss_log = train(\"./00007656_s010_t000_processed_data\", num_epochs=500, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotagem da perda ao longo do treinamento\n",
    "plt.plot(loss_log)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Progresso do Treinamento\")\n",
    "plt.savefig(\"loss_log.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração de amostras\n",
    "synthetic = diffusion.sample(num_samples=10, seq_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação espectral\n",
    "dataset = NeurophysioDataset(\"./00007656_s010_t000_processed_data\")\n",
    "real_sample = dataset[0].numpy()\n",
    "synthetic_sample = synthetic[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotagem dos sinais\n",
    "plt.figure(figsize=(12,6))\n",
    "for i, (real_channel, synth_channel) in enumerate(zip(real_sample, synthetic_sample)):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.plot(real_channel, label='Real')\n",
    "    plt.plot(synth_channel, label='Sintético')\n",
    "    plt.title(f\"Canal {i}\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"synthetic_signal_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da correlação temporal comparando dados reais e sintéticos\n",
    "def compute_temporal_correlation(real, synthetic):\n",
    "    correlations = []\n",
    "    for i, (real_channel, synth_channel) in enumerate(zip(real, synthetic)):\n",
    "            correlation = np.corrcoef(real_channel, synth_channel)[0, 1]  # Correlação entre os sinais\n",
    "            correlations.append((i, correlation))\n",
    "    return correlations\n",
    "\n",
    "correlations = compute_temporal_correlation(real_sample, synthetic_sample)\n",
    "for idx, corr in correlations:\n",
    "    print(f\"Correlação temporal (canal {idx}): {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(correlations, cmap='viridis', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Canal\")\n",
    "plt.ylabel(\"Canal\")\n",
    "plt.title(\"Correlação Temporal\")\n",
    "plt.savefig(\"heatmap_temporal_correlation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_real, psd_real = spectral_analysis(real_sample[0])\n",
    "f_syn, psd_syn = spectral_analysis(synthetic_sample[0])\n",
    "\n",
    "# Plotagem\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.semilogy(f_real, psd_real, label='Real')\n",
    "plt.semilogy(f_syn, psd_syn, label='Sintético')\n",
    "plt.title(\"Densidade Espectral de Potência (PSD)\")\n",
    "plt.xlabel(\"Frequência (Hz)\")\n",
    "plt.ylabel(\"Potência\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
